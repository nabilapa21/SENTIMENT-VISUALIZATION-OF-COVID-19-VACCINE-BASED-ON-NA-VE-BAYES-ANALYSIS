{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import ast\n",
    "import string\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import itertools\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cc ya banget ptn pamor kayak u pts pamor kayak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>cc tragedi trisakti peristiwa tembak mei hadap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cc huhu gue logo trisakti jeplak anjir suruh g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>cc berita bidang iii fh usakti seminar sosiali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>cc nder trisakti</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  x\n",
       "0           1  cc ya banget ptn pamor kayak u pts pamor kayak...\n",
       "1           2  cc tragedi trisakti peristiwa tembak mei hadap...\n",
       "2           3  cc huhu gue logo trisakti jeplak anjir suruh g...\n",
       "3           4  cc berita bidang iii fh usakti seminar sosiali...\n",
       "4           5                                   cc nder trisakti"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "df = pd.read_csv('textclean5.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menghapus tweet duplikat\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1748"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['x'].isnull()==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "x             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(x):\n",
    "    words = word_tokenize(x)\n",
    "    n=len(words)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#menghitung word length\n",
    "df['word_length'] = df['x'].apply(lambda x:count_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        15\n",
       "2        65\n",
       "3       171\n",
       "4       216\n",
       "5       189\n",
       "6       151\n",
       "7       130\n",
       "8       122\n",
       "9       128\n",
       "10      114\n",
       "11      100\n",
       "12       89\n",
       "13       96\n",
       "14       76\n",
       "15       49\n",
       "16       14\n",
       "17       16\n",
       "18        2\n",
       "19        2\n",
       "20        2\n",
       "2657      1\n",
       "Name: word_length, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_length'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word length 0 di drop\n",
    "df = df.drop(df[df['word_length']==0].index,axis=0)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#membuat kamus kata\n",
    "#meghitung berapa banyak kata yang ada di dataset\n",
    "\n",
    "word_dict = {}\n",
    "for i in range(0,len(df['x'])):\n",
    "    sentence = df['x'][i]\n",
    "    word_token = word_tokenize(sentence)\n",
    "    for j in word_token:\n",
    "        if j not in word_dict:\n",
    "            word_dict[j] = 1\n",
    "        else:\n",
    "            word_dict[j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3985"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import lexicon dan menghapus kata-kata negasi dari lexicon\n",
    "negasi = ['bukan','tidak','ga','gk']\n",
    "lexicon = pd.read_csv('modified_full_lexicon.csv')\n",
    "lexicon = lexicon.drop(lexicon[(lexicon['word'] == 'bukan')\n",
    "                              |(lexicon['word'] == 'tidak')\n",
    "                              |(lexicon['word'] == 'ga')|(lexicon['word'] == 'gk') ].index,axis=0)\n",
    "lexicon = lexicon.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10248"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "      <th>number_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hai</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>merekam</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ekstensif</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paripurna</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>detail</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pernik</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>belas</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>welas</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kabung</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rahayu</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  weight  number_of_words\n",
       "0        hai       3                1\n",
       "1    merekam       2                1\n",
       "2  ekstensif       3                1\n",
       "3  paripurna       1                1\n",
       "4     detail       2                1\n",
       "5     pernik       3                1\n",
       "6      belas       2                1\n",
       "7      welas       4                1\n",
       "8     kabung       1                1\n",
       "9     rahayu       4                1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_word = lexicon['word'].to_list()\n",
    "lexicon_num_words = lexicon['number_of_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10248"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicon_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3151"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#memeriksa apakah ada kata dalam kamus yang tidak termasuk dalam lexicon\n",
    "ns_words = []\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "for word in word_dict.keys():\n",
    "    if word not in lexicon_word:\n",
    "        kata_dasar = stemmer.stem(word)\n",
    "        if kata_dasar not in lexicon_word:\n",
    "            ns_words.append(word)\n",
    "len(ns_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9536\n",
       "2     686\n",
       "3      24\n",
       "4       2\n",
       "Name: number_of_words, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon['number_of_words'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'covid' in word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'budi baik' in lexicon_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#menghitung sentiment kata dengan menghitungnya mejadi lexicon\n",
    "sencol =[]\n",
    "senrow =np.array([])\n",
    "nsen = 0\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "sentiment_list = []\n",
    "\n",
    "#fungsi untuk menuliskan sentiment kata jika sudah ditemukan\n",
    "def found_word(ind,words,word,sen,sencol,sentiment,add):\n",
    "    # jika sudah termasuk dalam bag of words matrix, maka tambahkan nilainya\n",
    "    if word in sencol:\n",
    "        sen[sencol.index(word)] += 1\n",
    "    else:\n",
    "    #jika tidak tambahkan kata baru\n",
    "        sencol.append(word)\n",
    "        sen.append(1)\n",
    "        add += 1\n",
    "    #jika ada kata negasi sebelumnya, setiment adalah negasi sentimentnya\n",
    "    if (words[ind-1] in negasi):\n",
    "        sentiment += -lexicon['weight'][lexicon_word.index(word)]\n",
    "    else:\n",
    "        sentiment += lexicon['weight'][lexicon_word.index(word)]\n",
    "    \n",
    "    return sen,sencol,sentiment,add\n",
    "            \n",
    "# memeriksa setiap kata, jika muncul dalam lexicon, dan menghitung sentimennya\n",
    "for i in range(len(df)):\n",
    "    nsen = senrow.shape[0]\n",
    "    words = word_tokenize(df['x'][i])\n",
    "    sentiment = 0 \n",
    "    add = 0\n",
    "    prev = [0 for ii in range(len(words))]\n",
    "    n_words = len(words)\n",
    "    if len(sencol)>0:\n",
    "        sen =[0 for j in range(len(sencol))]\n",
    "    else:\n",
    "        sen =[]\n",
    "    \n",
    "    for word in words:\n",
    "        ind = words.index(word)\n",
    "        # periksa apakah kata termasuk dalam lexicon\n",
    "        if word in lexicon_word :\n",
    "            sen,sencol,sentiment,add= found_word(ind,words,word,sen,sencol,sentiment,add)\n",
    "        else:\n",
    "        # jika tidak cek kata dasarnya\n",
    "            kata_dasar = stemmer.stem(word)\n",
    "            if kata_dasar in lexicon_word:\n",
    "                sen,sencol,sentiment,add= found_word(ind,words,kata_dasar,sen,sencol,sentiment,add)\n",
    "        # jika masih negatif, coba cocokan kombinasi kata dengan kata yang berdekatan\n",
    "            elif(n_words>1):\n",
    "                if ind-1>-1:\n",
    "                    back_1    = words[ind-1]+' '+word\n",
    "                    if (back_1 in lexicon_word):\n",
    "                        sen,sencol,sentiment,add= found_word(ind,words,back_1,sen,sencol,sentiment,add)\n",
    "                    elif(ind-2>-1):\n",
    "                        back_2    = words[ind-2]+' '+back_1\n",
    "                        if back_2 in lexicon_word:\n",
    "                            sen,sencol,sentiment,add= found_word(ind,words,back_2,sen,sencol,sentiment,add)\n",
    "    # jika ada kata baru yang ditemukan, maka perluas matrix\n",
    "    if add>0:  \n",
    "        if i>0:\n",
    "            if (nsen==0):\n",
    "                senrow = np.zeros([i,add],dtype=int)\n",
    "            elif(i!=nsen):\n",
    "                padding_h = np.zeros([nsen,add],dtype=int)\n",
    "                senrow = np.hstack((senrow,padding_h))\n",
    "                padding_v = np.zeros([(i-nsen),senrow.shape[1]],dtype=int)\n",
    "                senrow = np.vstack((senrow,padding_v))\n",
    "            else:\n",
    "                padding =np.zeros([nsen,add],dtype=int)\n",
    "                senrow = np.hstack((senrow,padding))\n",
    "            senrow = np.vstack((senrow,sen))\n",
    "        if i==0:\n",
    "            senrow = np.array(sen).reshape(1,len(sen))\n",
    "    #jika tidak ada perbarui matriks lama\n",
    "    elif(nsen>0):\n",
    "        senrow = np.vstack((senrow,sen))\n",
    "        \n",
    "    sentiment_list.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9995"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9995\n"
     ]
    }
   ],
   "source": [
    "print(senrow.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sencol.append('sentiment')\n",
    "sentiment_array = np.array(sentiment_list).reshape(senrow.shape[0],1)\n",
    "sentiment_data = np.hstack((senrow,sentiment_array))\n",
    "df_sen = pd.DataFrame(sentiment_data,columns = sencol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yang</th>\n",
       "      <th>mengikuti</th>\n",
       "      <th>kegiatan</th>\n",
       "      <th>berkerumun</th>\n",
       "      <th>minta</th>\n",
       "      <th>usul</th>\n",
       "      <th>beli</th>\n",
       "      <th>buat</th>\n",
       "      <th>lancar</th>\n",
       "      <th>banding</th>\n",
       "      <th>...</th>\n",
       "      <th>bablas</th>\n",
       "      <th>abaikan</th>\n",
       "      <th>pinter</th>\n",
       "      <th>check</th>\n",
       "      <th>kredibel</th>\n",
       "      <th>pecat</th>\n",
       "      <th>ulah</th>\n",
       "      <th>pls</th>\n",
       "      <th>ngasih</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9995 rows × 1946 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      yang  mengikuti  kegiatan  berkerumun  minta  usul  beli  buat  lancar  \\\n",
       "0        1          1         1           1      1     0     0     0       0   \n",
       "1        0          0         0           0      0     1     1     1       1   \n",
       "2        0          0         0           0      0     0     0     0       0   \n",
       "3        0          0         0           0      0     0     0     0       0   \n",
       "4        0          0         0           0      0     0     0     0       0   \n",
       "...    ...        ...       ...         ...    ...   ...   ...   ...     ...   \n",
       "9990     0          0         0           0      0     0     0     0       0   \n",
       "9991     0          0         0           0      0     0     0     0       0   \n",
       "9992     0          0         0           0      0     0     0     0       0   \n",
       "9993     0          0         0           0      0     0     0     0       0   \n",
       "9994     0          0         0           0      0     0     0     0       0   \n",
       "\n",
       "      banding  ...  bablas  abaikan  pinter  check  kredibel  pecat  ulah  \\\n",
       "0           0  ...       0        0       0      0         0      0     0   \n",
       "1           0  ...       0        0       0      0         0      0     0   \n",
       "2           1  ...       0        0       0      0         0      0     0   \n",
       "3           0  ...       0        0       0      0         0      0     0   \n",
       "4           0  ...       0        0       0      0         0      0     0   \n",
       "...       ...  ...     ...      ...     ...    ...       ...    ...   ...   \n",
       "9990        0  ...       0        0       0      0         0      0     0   \n",
       "9991        0  ...       0        0       0      0         0      0     0   \n",
       "9992        0  ...       0        0       0      0         0      0     0   \n",
       "9993        0  ...       0        0       0      0         0      0     0   \n",
       "9994        0  ...       0        0       0      0         0      0     0   \n",
       "\n",
       "      pls  ngasih  sentiment  \n",
       "0       0       0         -1  \n",
       "1       0       0          9  \n",
       "2       0       0          3  \n",
       "3       0       0          1  \n",
       "4       0       0          5  \n",
       "...   ...     ...        ...  \n",
       "9990    0       0         12  \n",
       "9991    0       0         11  \n",
       "9992    0       0          1  \n",
       "9993    0       0         -1  \n",
       "9994    0       0          0  \n",
       "\n",
       "[9995 rows x 1946 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melihat sentimen dari tweet original\n",
    "\n",
    "cek_df = pd.DataFrame([])\n",
    "cek_df['tweet'] = df['tweet'].copy()\n",
    "cek_df['sentiment']  = df_sen['sentiment'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warga yang pernah mengikuti kegiatan berkerum...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kemenag Usul Beli Vaksin Covid-19 Buatan Saud...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @zamirmohyedin: Perbandingan antara vaksin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indonesia memiliki infrastruktur dan SDM mump...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perebutan vaksin Covid-19, mirip fenomena keb...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment\n",
       "0   Warga yang pernah mengikuti kegiatan berkerum...         -1\n",
       "1   Kemenag Usul Beli Vaksin Covid-19 Buatan Saud...          9\n",
       "2   RT @zamirmohyedin: Perbandingan antara vaksin...          3\n",
       "3   Indonesia memiliki infrastruktur dan SDM mump...          1\n",
       "4   Perebutan vaksin Covid-19, mirip fenomena keb...          5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cek_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cek_df.to_csv(\"vaksin_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
